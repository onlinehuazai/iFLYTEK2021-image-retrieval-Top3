{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, codecs, glob\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# torch.backends.cudnn.enabled = False\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XunFeiDataset(Dataset):\n",
    "    def __init__(self, img_path, img_group, transform):\n",
    "        self.img_path = img_path\n",
    "        self.transform = transform\n",
    "        self.group = img_group\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, self.group[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcModule(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s = 10, m = 0.2):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_normal_(self.weight)\n",
    "\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = torch.tensor(math.cos(math.pi - m))\n",
    "        self.mm = torch.tensor(math.sin(math.pi - m) * m)\n",
    "\n",
    "    def forward(self, inputs, labels):\n",
    "        cos_th = F.linear(inputs, F.normalize(self.weight))\n",
    "        cos_th = cos_th.clamp(-1, 1)\n",
    "        sin_th = torch.sqrt(1.0 - torch.pow(cos_th, 2))\n",
    "        cos_th_m = cos_th * self.cos_m - sin_th * self.sin_m\n",
    "        # print(type(cos_th), type(self.th), type(cos_th_m), type(self.mm))\n",
    "        cos_th_m = torch.where(cos_th > self.th, cos_th_m, cos_th - self.mm)\n",
    "        \n",
    "        cond_v = cos_th - self.th\n",
    "        cond = cond_v <= 0\n",
    "        cos_th_m[cond] = (cos_th - self.mm)[cond]\n",
    "\n",
    "        if labels.dim() == 1:\n",
    "            labels = labels.unsqueeze(-1)\n",
    "        onehot = torch.zeros(cos_th.size()).cuda()\n",
    "        labels = labels.type(torch.LongTensor).cuda()\n",
    "        onehot.scatter_(1, labels, 1.0)\n",
    "        outputs = onehot * cos_th_m + (1.0 - onehot) * cos_th\n",
    "        outputs = outputs * self.s\n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "class XunFeiNet_a(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XunFeiNet_a, self).__init__()\n",
    "                \n",
    "        model = timm.create_model('efficientnet_b3', pretrained=True)\n",
    "        self.model = model\n",
    "        model.classifier = torch.nn.Identity()\n",
    "        self.margin = ArcModule(in_features=1536, out_features = 1806)\n",
    "        \n",
    "    def forward(self, img, labels=None):        \n",
    "        feat = self.model(img)\n",
    "        \n",
    "        feat = F.normalize(feat)\n",
    "        if labels is not None:\n",
    "            return self.margin(feat, labels)\n",
    "        return feat\n",
    "\n",
    "\n",
    "\n",
    "class XunFeiNet_b(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XunFeiNet_b, self).__init__()\n",
    "                \n",
    "        model = timm.create_model('efficientnet_b3', pretrained=True)\n",
    "        self.model = model\n",
    "        model.classifier = torch.nn.Identity()\n",
    "        self.margin = ArcModule(in_features=1536, out_features = 1807)\n",
    "        \n",
    "    def forward(self, img, labels=None):        \n",
    "        feat = self.model(img)\n",
    "        \n",
    "        feat = F.normalize(feat)\n",
    "        if labels is not None:\n",
    "            return self.margin(feat, labels)\n",
    "        return feat\n",
    "    \n",
    "model_a = XunFeiNet_a().cuda()\n",
    "model_b = XunFeiNet_b().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = glob.glob('data/test_no_face/*')\n",
    "test_path.sort()\n",
    "test_path = np.array(test_path)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    XunFeiDataset(test_path, [0]*len(test_path),\n",
    "                        transforms.Compose([\n",
    "                        transforms.Resize((320, 320)),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=50, shuffle=False, num_workers=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "from sklearn.preprocessing import normalize\n",
    "model_a.load_state_dict(torch.load('one_effcient.pth'))\n",
    "model_a.eval()\n",
    "\n",
    "test_feats = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data[0].cuda()\n",
    "        feat = model_a(data)\n",
    "        test_feats.append(feat.data.cpu().numpy())\n",
    "        \n",
    "test_feats = np.vstack(test_feats)\n",
    "test_feats = normalize(test_feats)\n",
    "\n",
    "# 每折保存距离\n",
    "distance_1 = []\n",
    "for feat in test_feats[:]:\n",
    "    dis = np.dot(feat, test_feats.T)\n",
    "    feat_qe = np.multiply(dis[np.argsort(dis)[::-1][:2]].reshape(2, -1),\n",
    "            test_feats[np.argsort(dis)[::-1][:2]]).mean(0)\n",
    "    dis = np.dot(feat_qe, test_feats.T)\n",
    "    distance_1.append(dis)\n",
    "distance_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.load_state_dict(torch.load('two_final.pth'))\n",
    "model_a.eval()\n",
    "\n",
    "test_feats = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data[0].cuda()\n",
    "        feat = model_a(data)\n",
    "        test_feats.append(feat.data.cpu().numpy())\n",
    "        \n",
    "test_feats = np.vstack(test_feats)\n",
    "test_feats = normalize(test_feats)\n",
    "\n",
    "# 每折保存距离\n",
    "distance_2 = []\n",
    "for feat in test_feats[:]:\n",
    "    dis = np.dot(feat, test_feats.T)\n",
    "    feat_qe = np.multiply(dis[np.argsort(dis)[::-1][:2]].reshape(2, -1),\n",
    "        test_feats[np.argsort(dis)[::-1][:2]]).mean(0)\n",
    "    dis = np.dot(feat_qe, test_feats.T)\n",
    "    distance_2.append(dis)\n",
    "    \n",
    "distance_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.load_state_dict(torch.load('three_effcient.pth'))\n",
    "model_a.eval()\n",
    "\n",
    "test_feats = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data[0].cuda()\n",
    "        feat = model_a(data)\n",
    "        test_feats.append(feat.data.cpu().numpy())\n",
    "        \n",
    "test_feats = np.vstack(test_feats)\n",
    "test_feats = normalize(test_feats)\n",
    "\n",
    "# 每折保存距离\n",
    "distance_3 = []\n",
    "for feat in test_feats[:]:\n",
    "    dis = np.dot(feat, test_feats.T)\n",
    "    feat_qe = np.multiply(dis[np.argsort(dis)[::-1][:2]].reshape(2, -1),test_feats[np.argsort(dis)[::-1][:2]]).mean(0)\n",
    "    dis = np.dot(feat_qe, test_feats.T)\n",
    "    distance_3.append(dis)\n",
    "    \n",
    "distance_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b.load_state_dict(torch.load('four_final.pth'))\n",
    "model_b.eval()\n",
    "\n",
    "test_feats = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data[0].cuda()\n",
    "        feat = model_b(data)\n",
    "        test_feats.append(feat.data.cpu().numpy())\n",
    "        \n",
    "test_feats = np.vstack(test_feats)\n",
    "test_feats = normalize(test_feats)\n",
    "\n",
    "# 每折保存距离\n",
    "distance_4 = []\n",
    "for feat in test_feats[:]:\n",
    "    dis = np.dot(feat, test_feats.T)\n",
    "    feat_qe = np.multiply(dis[np.argsort(dis)[::-1][:2]].reshape(2, -1),\n",
    "            test_feats[np.argsort(dis)[::-1][:2]]).mean(0)\n",
    "    dis = np.dot(feat_qe, test_feats.T)\n",
    "    distance_4.append(dis)\n",
    "    \n",
    "distance_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b.load_state_dict(torch.load('five_final.pth'))\n",
    "model_b.eval()\n",
    "\n",
    "test_feats = []\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data[0].cuda()\n",
    "        feat = model_b(data)\n",
    "        test_feats.append(feat.data.cpu().numpy())\n",
    "        \n",
    "test_feats = np.vstack(test_feats)\n",
    "test_feats = normalize(test_feats)\n",
    "\n",
    "# 每折保存距离\n",
    "distance_5 = []\n",
    "for feat in test_feats[:]:\n",
    "    dis = np.dot(feat, test_feats.T)\n",
    "    feat_qe = np.multiply(dis[np.argsort(dis)[::-1][:2]].reshape(2, -1),test_feats[np.argsort(dis)[::-1][:2]]).mean(0)\n",
    "    dis = np.dot(feat_qe, test_feats.T)\n",
    "    distance_5.append(dis)\n",
    "    \n",
    "distance_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_distance = []\n",
    "for i in range(len(distance_5)):\n",
    "    test_distance.append((0.1 * distance_1[i] + 0.25 * distance_2[i] + 0.15 * distance_3[i] + 0.25 * distance_4[i] + 0.25 * distance_5[i]))\n",
    "    \n",
    "test_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做了扩展查询\n",
    "test_submit = []\n",
    "for i in range(len(test_path)):\n",
    "    dis = test_distance[i]\n",
    "    path = test_path[i]\n",
    "    pred = [x.split('/')[-1] for x in test_path[np.where(dis > 0.59)[0]]]\n",
    "    \n",
    "    if len(pred) <= 1:\n",
    "        ids = dis.argsort()[::-1]\n",
    "        pred = [x.split('/')[-1] for x in test_path[ids[:2]]]\n",
    "    print(pred)\n",
    "    test_submit.append([\n",
    "        path.split('/')[-1],\n",
    "        pred\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submit = pd.DataFrame(test_submit, columns=['name', 'label'])\n",
    "test_submit['label'] = test_submit['label'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "test_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submit.to_csv('submit.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
